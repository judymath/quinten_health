{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import unicodedata\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import nltk\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/madhuranirale/Desktop/HEC-T1/Quinten/raw_data_healthcare.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc90c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['text_index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1104836",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979599c0",
   "metadata": {},
   "source": [
    "## Filtering required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b259cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = data['medication'].str.split(r'(?i)for',1,expand=True)\n",
    "data['drug'] = split_data[0]\n",
    "data['illness'] = split_data[1]\n",
    "\n",
    "# Define the regex pattern for filtering\n",
    "pattern = r'(?i)Ulcerative Colitis|Crohn\\'s Disease'\n",
    "\n",
    "# Use str.contains() to filter the data\n",
    "data = data[data['illness'].str.contains(pattern, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('shortlisted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41c9df",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498877bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()\n",
    "#Valid ratings = 281-14 = 267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642336ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This barplot show the count of illnesses the people are suffering.\n",
    "cond = dict(data['illness'].value_counts())\n",
    "top_condition = list(cond.keys())[0:10]\n",
    "values = list(cond.values())[0:10]\n",
    "sns.set(style = 'darkgrid', font_scale = 1.3)\n",
    "plt.rcParams['figure.figsize'] = [7, 5]\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "sns_ = sns.barplot(x = top_condition, y = values, palette = 'winter')\n",
    "sns_.set_title(\"Conditions vs count\",fontsize=12)\n",
    "sns_.set_xlabel(\"Illness\",fontsize=10)\n",
    "sns_.set_ylabel(\"Count\",fontsize=10)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2049be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most frequently reviewed drugs\n",
    "top_drugs = data['drug'].value_counts()\n",
    "sns.barplot(x=top_drugs.index, y=top_drugs.values)\n",
    "plt.title('Reviewed Drugs Count', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Drug Name',fontsize=10)\n",
    "plt.ylabel('Count',fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f598c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This barplot shows the top drugs with the 10/10 rating\n",
    "\n",
    "# Setting the Parameter\n",
    "sns.set(font_scale = 1.2, style = 'darkgrid')\n",
    "plt.rcParams['figure.figsize'] = [7, 5]\n",
    "\n",
    "rating = dict(data.loc[data.rate == 10, \"drug\"].value_counts())\n",
    "drugname = list(rating.keys())\n",
    "drug_rating = list(rating.values())\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "sns_rating = sns.barplot(x = drugname, y = drug_rating)\n",
    "\n",
    "sns_rating.set_title('Top drugs with 10/10 rating',fontsize=12)\n",
    "sns_rating.set_ylabel(\"Number of Ratings\",fontsize=10)\n",
    "sns_rating.set_xlabel(\"Drug Names\",fontsize=10)\n",
    "plt.setp(sns_rating.get_xticklabels(), rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c356fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each rating\n",
    "rating_counts = data['rate'].value_counts().sort_index()\n",
    "\n",
    "# Create a donut chart with a legend\n",
    "fig, ax = plt.subplots()\n",
    "wedges, texts, autotexts = ax.pie(rating_counts, labels=None, autopct='', startangle=140, wedgeprops=dict(width=0.3))\n",
    "\n",
    "# Calculate percentages and set labels inside the fractions\n",
    "total_ratings = sum(rating_counts)\n",
    "percentages = [(count / total_ratings * 100) for count in rating_counts]\n",
    "\n",
    "labels = [f\"{rating} ({percent:.1f}%)\" for rating, percent in zip(rating_counts.index, percentages)]\n",
    "\n",
    "# Set labels and rotate them\n",
    "ax.legend(wedges, labels, title=\"Ratings\", loc=\"center left\", bbox_to_anchor=(0.9,0.7),prop={'size': 8},title_fontsize=10)\n",
    "plt.setp(autotexts, size=10, weight=\"bold\")\n",
    "\n",
    "plt.title('Distribution of Ratings', fontsize=12)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that the donut chart is clear.\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a080a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A countplot of the ratings so we can see the distribution of the ratings\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "sns.set(font_scale=1.2, style='whitegrid')\n",
    "\n",
    "sns_plot = sns.distplot(data['rate'], color='skyblue')\n",
    "sns_plot.set(xlim=(0, 12))\n",
    "\n",
    "sns_plot.set_title('Distribution of Ratings')\n",
    "sns_plot.set_xlabel(\"Rating\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ab183",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('shortlisted.csv')\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9444c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['rate'] >= 5, 'review_sentiment'] = 1\n",
    "data.loc[data['rate'] < 5, 'review_sentiment'] = 0\n",
    "\n",
    "data['review_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(review): \n",
    "    # changing to lower case\n",
    "    lower = review.str.lower()\n",
    "    \n",
    "    # Replacing the repeating pattern of &#039;\n",
    "    pattern_remove = lower.str.replace(\"&#039;\", \"\")\n",
    "    \n",
    "    # Removing all the special Characters\n",
    "    special_remove = pattern_remove.str.replace(r'[^\\w\\d\\s]',' ')\n",
    "    \n",
    "    # Removing all the non ASCII characters\n",
    "    ascii_remove = special_remove.str.replace(r'[^\\x00-\\x7F]+',' ')\n",
    "    \n",
    "    # Removing the leading and trailing Whitespaces\n",
    "    whitespace_remove = ascii_remove.str.replace(r'^\\s+|\\s+?$','')\n",
    "    \n",
    "    # Replacing multiple Spaces with Single Space\n",
    "    multiw_remove = whitespace_remove.str.replace(r'\\s+',' ')\n",
    "    \n",
    "    # Replacing Two or more dots with one\n",
    "    dataframe = multiw_remove.str.replace(r'\\.{2,}', ' ')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review_clean'] = remove_noise(data['comment'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96146b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['review_clean'] = data['review_clean'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97769584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a function for lemmatization using spaCy\n",
    "def lemmatize_with_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = \" \".join([token.lemma_ if token.lemma_ != \"-PRON-\" else token.text for token in doc])\n",
    "    return lemmatized_text\n",
    "\n",
    "# Apply lemmatization to your DataFrame\n",
    "data['review'] = data['review_clean'].apply(lemmatize_with_spacy)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93796b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(review):\n",
    "    # Sentiment polarity of the reviews\n",
    "    pol = []\n",
    "    for i in review:\n",
    "        analysis = TextBlob(i)\n",
    "        pol.append(analysis.sentiment.polarity)\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cafb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = sentiment(data['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2216c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment_clean'] = sentiment(data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a620a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the reviews without removing the stop words and using snowball stemmer\n",
    "data['review_clean_ss'] = remove_noise(data['comment'])\n",
    "data['sentiment_clean_ss'] = sentiment(data['review_clean_ss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ca9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word count in each review\n",
    "data['count_word']=data[\"review_clean_ss\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#Unique word count \n",
    "data['count_unique_word']=data[\"review_clean_ss\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "#Letter count\n",
    "data['count_letters']=data[\"review_clean_ss\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "#punctuation count\n",
    "data[\"count_punctuations\"] = data[\"comment\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "#upper case words count\n",
    "data[\"count_words_upper\"] = data[\"comment\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "#title case words count\n",
    "data[\"count_words_title\"] = data[\"comment\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "#Number of stopwords\n",
    "data[\"count_stopwords\"] = data[\"comment\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]))\n",
    "\n",
    "#Average length of the words\n",
    "data[\"mean_word_len\"] = data[\"review_clean_ss\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baad2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f9558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
